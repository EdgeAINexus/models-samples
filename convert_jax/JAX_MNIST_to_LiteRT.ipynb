{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vD3L4qeREvg"
      },
      "source": [
        "##### Copyright 2024 The AI Edge Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qLCxmWRyRMZE",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4k5PoHrgJQOU"
      },
      "source": [
        "# Jax Model Conversion For LiteRT\n",
        "## Overview\n",
        "Note: This API is new and we recommend using via pip install tf-nightly. Also, the API is still experimental and subject to changes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lq-T8XZMJ-zv"
      },
      "source": [
        "## Prerequisites\n",
        "It's recommended to try this feature with the newest TensorFlow nightly pip build."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EV04hKdrnE4f"
      },
      "outputs": [],
      "source": [
        "!pip install jax --upgrade\n",
        "!pip install ai-edge-litert\n",
        "!pip install orbax-export --upgrade\n",
        "!pip install tf-nightly --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vsilblGuGQa2"
      },
      "outputs": [],
      "source": [
        "# Make sure your JAX version is at least 0.4.20 or above.\n",
        "import jax\n",
        "jax.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j9_CVA0THQNc"
      },
      "outputs": [],
      "source": [
        "from orbax.export import ExportManager\n",
        "from orbax.export import JaxModule\n",
        "from orbax.export import ServingConfig\n",
        "from orbax.export import constants\n",
        "\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "\n",
        "import time\n",
        "import functools\n",
        "import itertools\n",
        "\n",
        "import numpy as np\n",
        "import numpy.random as npr\n",
        "\n",
        "import jax.numpy as jnp\n",
        "from jax import jit, grad, random\n",
        "from jax.example_libraries import optimizers\n",
        "from jax.example_libraries import stax"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAeY43k9KM55"
      },
      "source": [
        "## Data Preparation\n",
        "Download the MNIST data with Keras dataset and run that data through a pre-processing step. This dataset consists of multiple images that are 28x28 pixels and grayscaled (only having one color channel from black to white) representing hand drawn digits from 0 to 9.\n",
        "\n",
        "During the pre-processing step, the images will be normalized so that their gray color channel will change from 0->255 to 0.0->1.0. This decreases training time.\n",
        "\n",
        "The model will also use One Hot Encoding. This filters predictions to the most likely prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hdJIt3Da2Qn1"
      },
      "outputs": [],
      "source": [
        "# Create a one-hot encoding of x of size k.\n",
        "def _one_hot(x, k, dtype=np.float32):\n",
        "  return np.array(x[:, None] == np.arange(k), dtype)\n",
        "\n",
        "# JAX doesn't have its own data loader, so you can use Keras here.\n",
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# Normalize the image pixels to a range of 0.0 to 1.0\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "train_images = train_images.astype(np.float32)\n",
        "test_images = test_images.astype(np.float32)\n",
        "\n",
        "train_labels = _one_hot(train_labels, 10)\n",
        "test_labels = _one_hot(test_labels, 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code block is a simple utility to display a set of the MNIST dataset images."
      ],
      "metadata": {
        "id": "J_bJvaWrzXr7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Draws out some of the data in the training dataset.\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "rows = 3\n",
        "cols = 7\n",
        "\n",
        "for i in range(rows):\n",
        "  for j in range(cols):\n",
        "    index = i * cols + j\n",
        "    if index < len(train_images):\n",
        "      plt.subplot(rows, cols, index + 1)\n",
        "      plt.imshow(train_images[index], cmap='gray')\n",
        "      plt.title(f\"Label: {np.argmax(train_labels[index])}\")\n",
        "      plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uyyFkg4Zpe3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eFhx85YKlEY"
      },
      "source": [
        "## Build the MNIST model with Jax"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This block outlines the loss and accuracy functions for training a new classification model, as well as defines the shape of the model layers."
      ],
      "metadata": {
        "id": "v0lIlmVgz_0g"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mi3TKB9nnQdK"
      },
      "outputs": [],
      "source": [
        "# Loss function: Measures how well the model's predictions match expected outputs.\n",
        "def loss(params, batch):\n",
        "  inputs, targets = batch\n",
        "  preds = predict(params, inputs)\n",
        "  return -jnp.mean(jnp.sum(preds * targets, axis=1))\n",
        "\n",
        "# Accuracy function: Average number of times the predictec class matches the true class\n",
        "def accuracy(params, batch):\n",
        "  inputs, targets = batch\n",
        "  # Finds the highest value in the output targets, which is the true value\n",
        "  target_class = jnp.argmax(targets, axis=1)\n",
        "  # Gets the primary predicted value from classification\n",
        "  predicted_class = jnp.argmax(predict(params, inputs), axis=1)\n",
        "  return jnp.mean(predicted_class == target_class)\n",
        "\n",
        "\n",
        "init_random_params, predict = stax.serial(\n",
        "    stax.Flatten, # turns input data into a vector (1D array)\n",
        "    stax.Dense(1024), stax.Relu, # Create two dense layers with ReLU activation\n",
        "    stax.Dense(1024), stax.Relu,\n",
        "    stax.Dense(10), stax.LogSoftmax) # Final layer condenses predictions into one of ten potential output classifications (0->9)\n",
        "\n",
        "# Pseudo random number generator used for initializing values\n",
        "rng = random.PRNGKey(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRtnOBdJLd63"
      },
      "source": [
        "## Train & Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SWbYRyj7LYZt"
      },
      "outputs": [],
      "source": [
        "step_size = 0.001 # Learning rate - smaller means slower but more stable learning\n",
        "num_epochs = 10\n",
        "batch_size = 128\n",
        "momentum_mass = 0.9 # Momentum optimization algorithm - helps converge faster\n",
        "\n",
        "# Data setup\n",
        "num_train = train_images.shape[0]\n",
        "num_complete_batches, leftover = divmod(num_train, batch_size)\n",
        "num_batches = num_complete_batches + bool(leftover)\n",
        "\n",
        "def data_stream():\n",
        "  rng = npr.RandomState(0)\n",
        "  while True:\n",
        "    perm = rng.permutation(num_train)\n",
        "    for i in range(num_batches):\n",
        "      batch_idx = perm[i * batch_size:(i + 1) * batch_size]\n",
        "      yield train_images[batch_idx], train_labels[batch_idx]\n",
        "batches = data_stream()\n",
        "\n",
        "# Optimizer setup\n",
        "opt_init, opt_update, get_params = optimizers.momentum(step_size, mass=momentum_mass)\n",
        "\n",
        "# Performs a single training step. Gets the current parameters, calculates\n",
        "# gradient of the loss function, then updates the optimizer state and model parameters\n",
        "@jit\n",
        "def update(i, opt_state, batch):\n",
        "  params = get_params(opt_state)\n",
        "  return opt_update(i, grad(loss)(params, batch), opt_state)\n",
        "\n",
        "# Run the training loop!\n",
        "_, init_params = init_random_params(rng, (-1, 28 * 28))\n",
        "opt_state = opt_init(init_params)\n",
        "itercount = itertools.count()\n",
        "\n",
        "print(\"\\nStarting training...\")\n",
        "for epoch in range(num_epochs):\n",
        "  start_time = time.time()\n",
        "  for _ in range(num_batches):\n",
        "    opt_state = update(next(itercount), opt_state, next(batches))\n",
        "  epoch_time = time.time() - start_time\n",
        "\n",
        "  params = get_params(opt_state)\n",
        "  train_acc = accuracy(params, (train_images, train_labels))\n",
        "  test_acc = accuracy(params, (test_images, test_labels))\n",
        "  print(\"Epoch {} in {:0.2f} sec\".format(epoch, epoch_time))\n",
        "  print(\"Training set accuracy {}\".format(train_acc))\n",
        "  print(\"Test set accuracy {}\".format(test_acc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Y1OZBhfQhOj"
      },
      "source": [
        "## Convert to a tflite model.\n",
        "\n",
        "Using the `orbax` library, you can export the newly trained `JAX` model to a TensorFlow `SavedModel` file. Once you have a `SavedModel`, you can convert it to a `.tflite` file that can work with the LiteRT interpreter.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6pcqKZqdNTmn"
      },
      "outputs": [],
      "source": [
        "# This line bridges JAX to TensorFlow\n",
        "# Key point: `params` is everything that was learned during training. This is the\n",
        "# core part of what you just accomplished.\n",
        "# `predict` is the JAX function that does inference.\n",
        "jax_module = JaxModule(params, predict, input_polymorphic_shape='b, ...')\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_concrete_functions(\n",
        "    [\n",
        "        jax_module.methods[constants.DEFAULT_METHOD_KEY].get_concrete_function(\n",
        "            tf.TensorSpec(shape=(1, 28, 28), dtype=tf.float32, name=\"input\")\n",
        "        )\n",
        "    ],\n",
        "    trackable_obj=tf.function() # Added empty trackable_obj argument\n",
        ")\n",
        "\n",
        "tflite_model = converter.convert()\n",
        "with open('jax_mnist.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqEhzaJPSPS1"
      },
      "source": [
        "## Check the Converted TFLite Model\n",
        "Next you can compare the converted model's results with the Jax model. This first block defines a utility to perform the prediction inference."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_image_class(image_path, model_path):\n",
        "\n",
        "  try:\n",
        "    # Load the TFLite model and allocate tensors.\n",
        "    interpreter = Interpreter(model_path=model_path)\n",
        "    interpreter.allocate_tensors()\n",
        "\n",
        "    # Get input and output tensors.\n",
        "    input_details = interpreter.get_input_details()\n",
        "    output_details = interpreter.get_output_details()\n",
        "\n",
        "    # Load the test image.\n",
        "    img = Image.open(image_path).convert('L').resize((28, 28))\n",
        "    img_array = np.array(img)\n",
        "    img_array = img_array / 255.0\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    img_array = img_array.astype(np.float32)\n",
        "\n",
        "    # Set the tensor to the input tensor and run inference.\n",
        "    interpreter.set_tensor(input_details[0]['index'], img_array)\n",
        "    interpreter.invoke()\n",
        "\n",
        "    # Get the output tensor.\n",
        "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "\n",
        "    # Get the predicted class\n",
        "    predicted_class = np.argmax(output_data)\n",
        "    print(\"Predicted class:\", predicted_class)\n",
        "\n",
        "  except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ],
      "metadata": {
        "id": "iKqKZZN7td0b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can download a pre-drawn image for testing that Google has provided, or load your own hand drawn monochronmatic image into the `/content/` directory."
      ],
      "metadata": {
        "id": "xZfUExBQ1Wha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://storage.googleapis.com/ai-edge/models-samples/jax_converter/jax_to_litert_conversion_test/7.png -O /content/7.png"
      ],
      "metadata": {
        "id": "TXa1OkQZ3onF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ai_edge_litert.interpreter import Interpreter\n",
        "\n",
        "# Example usage\n",
        "# Replace with your image and model paths\n",
        "image_path = \"/content/7.png\"\n",
        "model_path = \"/content/jax_mnist.tflite\"\n",
        "\n",
        "predict_image_class(image_path, model_path)"
      ],
      "metadata": {
        "id": "UoohrrHusvS9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qy9Gp4H2SjBL"
      },
      "source": [
        "## Optimize the Model\n",
        "We will provide a `representative_dataset` to do post-training quantiztion to optimize the model. This will reduce the model size to roughly a quarter.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def representative_dataset():\n",
        "  for i in range(1000):\n",
        "    x = train_images[i:i+1]\n",
        "    yield [x]\n",
        "\n",
        "\n",
        "# Create a orbax.export.JaxModule that wraps the given JAX function and params into a TF.Module\n",
        "jax_module = JaxModule(params, predict)\n",
        "\n",
        "# Instanciate tf.lite.TFLiteConverter object from the default_signature in the above module\n",
        "converter = tf.lite.TFLiteConverter.from_concrete_functions(\n",
        "    [\n",
        "        jax_module.methods[constants.DEFAULT_METHOD_KEY].get_concrete_function(\n",
        "            tf.TensorSpec(shape=(1, 28, 28), dtype=tf.float32, name=\"input\")\n",
        "        )\n",
        "    ],\n",
        "    trackable_obj=tf.function() # Added empty trackable_obj argument\n",
        ")\n",
        "\n",
        "# Apply optimization settings and convert the model\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.representative_dataset = representative_dataset\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "tflite_quant_model = converter.convert()\n",
        "\n",
        "# Save the serialized model contents to a .tflite flatbuffer\n",
        "with open('jax_mnist_quant.tflite', 'wb') as f:\n",
        "  f.write(tflite_quant_model)"
      ],
      "metadata": {
        "id": "-sSPO7xsmYjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15xQR3JZS8TV"
      },
      "source": [
        "## Evaluate the Optimized Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X3oOm0OaevD6"
      },
      "outputs": [],
      "source": [
        "image_path = \"/content/7.png\"\n",
        "model_path = \"/content/jax_mnist_quant.tflite\"\n",
        "\n",
        "predict_image_class(image_path, model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqHXCNa3myor"
      },
      "source": [
        "## Compare the Quantized Model size\n",
        "We should be able to see the quantized model is four times smaller than the original model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imFPw007juVG"
      },
      "outputs": [],
      "source": [
        "!du -h jax_mnist.tflite\n",
        "!du -h jax_mnist_quant.tflite"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('jax_mnist.tflite')\n",
        "files.download('jax_mnist_quant.tflite')"
      ],
      "metadata": {
        "id": "LVxWUI78erIF"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}